{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Prediction of Sharpe ratio for blends of quantitative strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1120,
   "metadata": {
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from xgboost import XGBRegressor \n",
    "\n",
    "from joblib import load\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {
    "hide_input": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Data/Training_Input_2dx8C9Q.csv\")\n",
    "y = pd.read_csv(\"Data/Training_Output_IJhBXtA.csv\")\n",
    "test = pd.read_csv(\"Data/Testing_Input_dPKY3Rf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 218)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>weight_I_1</th>\n",
       "      <th>weight_I_2</th>\n",
       "      <th>weight_I_3</th>\n",
       "      <th>weight_I_4</th>\n",
       "      <th>weight_I_5</th>\n",
       "      <th>weight_I_6</th>\n",
       "      <th>weight_I_7</th>\n",
       "      <th>I_1_lag_20</th>\n",
       "      <th>I_1_lag_19</th>\n",
       "      <th>...</th>\n",
       "      <th>X_3_lag_9</th>\n",
       "      <th>X_3_lag_8</th>\n",
       "      <th>X_3_lag_7</th>\n",
       "      <th>X_3_lag_6</th>\n",
       "      <th>X_3_lag_5</th>\n",
       "      <th>X_3_lag_4</th>\n",
       "      <th>X_3_lag_3</th>\n",
       "      <th>X_3_lag_2</th>\n",
       "      <th>X_3_lag_1</th>\n",
       "      <th>X_3_lag_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.047398</td>\n",
       "      <td>...</td>\n",
       "      <td>101.383783</td>\n",
       "      <td>102.054669</td>\n",
       "      <td>102.375596</td>\n",
       "      <td>103.148605</td>\n",
       "      <td>103.148605</td>\n",
       "      <td>103.046483</td>\n",
       "      <td>103.075701</td>\n",
       "      <td>103.134043</td>\n",
       "      <td>103.221509</td>\n",
       "      <td>103.338192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.912339</td>\n",
       "      <td>...</td>\n",
       "      <td>100.911142</td>\n",
       "      <td>100.938707</td>\n",
       "      <td>100.993926</td>\n",
       "      <td>101.132016</td>\n",
       "      <td>100.745489</td>\n",
       "      <td>100.524617</td>\n",
       "      <td>100.303743</td>\n",
       "      <td>100.276090</td>\n",
       "      <td>100.303743</td>\n",
       "      <td>100.554527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.481681</td>\n",
       "      <td>...</td>\n",
       "      <td>100.373084</td>\n",
       "      <td>100.581716</td>\n",
       "      <td>100.313489</td>\n",
       "      <td>100.790251</td>\n",
       "      <td>101.013756</td>\n",
       "      <td>100.686030</td>\n",
       "      <td>100.686030</td>\n",
       "      <td>100.060233</td>\n",
       "      <td>99.747384</td>\n",
       "      <td>99.970889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.124618</td>\n",
       "      <td>...</td>\n",
       "      <td>100.844136</td>\n",
       "      <td>101.040072</td>\n",
       "      <td>101.055122</td>\n",
       "      <td>101.567682</td>\n",
       "      <td>101.703322</td>\n",
       "      <td>101.974603</td>\n",
       "      <td>101.733422</td>\n",
       "      <td>101.838963</td>\n",
       "      <td>102.080144</td>\n",
       "      <td>101.688272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>99.665093</td>\n",
       "      <td>99.482389</td>\n",
       "      <td>99.604192</td>\n",
       "      <td>100.030499</td>\n",
       "      <td>99.847797</td>\n",
       "      <td>100.426310</td>\n",
       "      <td>100.426310</td>\n",
       "      <td>100.822217</td>\n",
       "      <td>100.913521</td>\n",
       "      <td>100.852619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  weight_I_1  weight_I_2  weight_I_3  weight_I_4  weight_I_5  weight_I_6  \\\n",
       "0   0        0.15        0.00        0.05        0.80        0.00         0.0   \n",
       "1   1        0.00        0.00        0.00        0.40        0.25         0.0   \n",
       "2   2        0.85        0.00        0.00        0.15        0.00         0.0   \n",
       "3   3        0.00        0.00        0.70        0.05        0.25         0.0   \n",
       "4   4        0.00        0.55        0.05        0.00        0.00         0.0   \n",
       "\n",
       "   weight_I_7  I_1_lag_20  I_1_lag_19  ...   X_3_lag_9   X_3_lag_8  \\\n",
       "0        0.00       100.0  100.047398  ...  101.383783  102.054669   \n",
       "1        0.35       100.0   99.912339  ...  100.911142  100.938707   \n",
       "2        0.00       100.0   99.481681  ...  100.373084  100.581716   \n",
       "3        0.00       100.0  100.124618  ...  100.844136  101.040072   \n",
       "4        0.40       100.0  100.000000  ...   99.665093   99.482389   \n",
       "\n",
       "    X_3_lag_7   X_3_lag_6   X_3_lag_5   X_3_lag_4   X_3_lag_3   X_3_lag_2  \\\n",
       "0  102.375596  103.148605  103.148605  103.046483  103.075701  103.134043   \n",
       "1  100.993926  101.132016  100.745489  100.524617  100.303743  100.276090   \n",
       "2  100.313489  100.790251  101.013756  100.686030  100.686030  100.060233   \n",
       "3  101.055122  101.567682  101.703322  101.974603  101.733422  101.838963   \n",
       "4   99.604192  100.030499   99.847797  100.426310  100.426310  100.822217   \n",
       "\n",
       "    X_3_lag_1   X_3_lag_0  \n",
       "0  103.221509  103.338192  \n",
       "1  100.303743  100.554527  \n",
       "2   99.747384   99.970889  \n",
       "3  102.080144  101.688272  \n",
       "4  100.913521  100.852619  \n",
       "\n",
       "[5 rows x 218 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-12.007941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.294867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.652308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.412364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8.517471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     Target\n",
       "0   0 -12.007941\n",
       "1   1   2.294867\n",
       "2   2   0.652308\n",
       "3   3   2.412364\n",
       "4   4   8.517471"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4450, 218)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "data = data.set_index(\"ID\")\n",
    "y = y.set_index(\"ID\")\n",
    "test = test.set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 0 to 9999\n",
      "Columns: 217 entries, weight_I_1 to X_3_lag_0\n",
      "dtypes: float64(217)\n",
      "memory usage: 16.6 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 0 to 9999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Target  10000 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 156.2 KB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False False\n"
     ]
    }
   ],
   "source": [
    "# Missing values ?\n",
    "print(True in data.isna(), True in y.isna(), True in test.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weight_I_1',\n",
       " 'weight_I_2',\n",
       " 'weight_I_3',\n",
       " 'weight_I_4',\n",
       " 'weight_I_5',\n",
       " 'weight_I_6',\n",
       " 'weight_I_7',\n",
       " 'I_1_lag_20',\n",
       " 'I_1_lag_19',\n",
       " 'I_1_lag_18',\n",
       " 'I_1_lag_17',\n",
       " 'I_1_lag_16',\n",
       " 'I_1_lag_15',\n",
       " 'I_1_lag_14',\n",
       " 'I_1_lag_13',\n",
       " 'I_1_lag_12',\n",
       " 'I_1_lag_11',\n",
       " 'I_1_lag_10',\n",
       " 'I_1_lag_9',\n",
       " 'I_1_lag_8',\n",
       " 'I_1_lag_7',\n",
       " 'I_1_lag_6',\n",
       " 'I_1_lag_5',\n",
       " 'I_1_lag_4',\n",
       " 'I_1_lag_3',\n",
       " 'I_1_lag_2',\n",
       " 'I_1_lag_1',\n",
       " 'I_1_lag_0',\n",
       " 'I_2_lag_20',\n",
       " 'I_2_lag_19',\n",
       " 'I_2_lag_18',\n",
       " 'I_2_lag_17',\n",
       " 'I_2_lag_16',\n",
       " 'I_2_lag_15',\n",
       " 'I_2_lag_14',\n",
       " 'I_2_lag_13',\n",
       " 'I_2_lag_12',\n",
       " 'I_2_lag_11',\n",
       " 'I_2_lag_10',\n",
       " 'I_2_lag_9',\n",
       " 'I_2_lag_8',\n",
       " 'I_2_lag_7',\n",
       " 'I_2_lag_6',\n",
       " 'I_2_lag_5',\n",
       " 'I_2_lag_4',\n",
       " 'I_2_lag_3',\n",
       " 'I_2_lag_2',\n",
       " 'I_2_lag_1',\n",
       " 'I_2_lag_0',\n",
       " 'I_3_lag_20',\n",
       " 'I_3_lag_19',\n",
       " 'I_3_lag_18',\n",
       " 'I_3_lag_17',\n",
       " 'I_3_lag_16',\n",
       " 'I_3_lag_15',\n",
       " 'I_3_lag_14',\n",
       " 'I_3_lag_13',\n",
       " 'I_3_lag_12',\n",
       " 'I_3_lag_11',\n",
       " 'I_3_lag_10',\n",
       " 'I_3_lag_9',\n",
       " 'I_3_lag_8',\n",
       " 'I_3_lag_7',\n",
       " 'I_3_lag_6',\n",
       " 'I_3_lag_5',\n",
       " 'I_3_lag_4',\n",
       " 'I_3_lag_3',\n",
       " 'I_3_lag_2',\n",
       " 'I_3_lag_1',\n",
       " 'I_3_lag_0',\n",
       " 'I_4_lag_20',\n",
       " 'I_4_lag_19',\n",
       " 'I_4_lag_18',\n",
       " 'I_4_lag_17',\n",
       " 'I_4_lag_16',\n",
       " 'I_4_lag_15',\n",
       " 'I_4_lag_14',\n",
       " 'I_4_lag_13',\n",
       " 'I_4_lag_12',\n",
       " 'I_4_lag_11',\n",
       " 'I_4_lag_10',\n",
       " 'I_4_lag_9',\n",
       " 'I_4_lag_8',\n",
       " 'I_4_lag_7',\n",
       " 'I_4_lag_6',\n",
       " 'I_4_lag_5',\n",
       " 'I_4_lag_4',\n",
       " 'I_4_lag_3',\n",
       " 'I_4_lag_2',\n",
       " 'I_4_lag_1',\n",
       " 'I_4_lag_0',\n",
       " 'I_5_lag_20',\n",
       " 'I_5_lag_19',\n",
       " 'I_5_lag_18',\n",
       " 'I_5_lag_17',\n",
       " 'I_5_lag_16',\n",
       " 'I_5_lag_15',\n",
       " 'I_5_lag_14',\n",
       " 'I_5_lag_13',\n",
       " 'I_5_lag_12',\n",
       " 'I_5_lag_11',\n",
       " 'I_5_lag_10',\n",
       " 'I_5_lag_9',\n",
       " 'I_5_lag_8',\n",
       " 'I_5_lag_7',\n",
       " 'I_5_lag_6',\n",
       " 'I_5_lag_5',\n",
       " 'I_5_lag_4',\n",
       " 'I_5_lag_3',\n",
       " 'I_5_lag_2',\n",
       " 'I_5_lag_1',\n",
       " 'I_5_lag_0',\n",
       " 'I_6_lag_20',\n",
       " 'I_6_lag_19',\n",
       " 'I_6_lag_18',\n",
       " 'I_6_lag_17',\n",
       " 'I_6_lag_16',\n",
       " 'I_6_lag_15',\n",
       " 'I_6_lag_14',\n",
       " 'I_6_lag_13',\n",
       " 'I_6_lag_12',\n",
       " 'I_6_lag_11',\n",
       " 'I_6_lag_10',\n",
       " 'I_6_lag_9',\n",
       " 'I_6_lag_8',\n",
       " 'I_6_lag_7',\n",
       " 'I_6_lag_6',\n",
       " 'I_6_lag_5',\n",
       " 'I_6_lag_4',\n",
       " 'I_6_lag_3',\n",
       " 'I_6_lag_2',\n",
       " 'I_6_lag_1',\n",
       " 'I_6_lag_0',\n",
       " 'I_7_lag_20',\n",
       " 'I_7_lag_19',\n",
       " 'I_7_lag_18',\n",
       " 'I_7_lag_17',\n",
       " 'I_7_lag_16',\n",
       " 'I_7_lag_15',\n",
       " 'I_7_lag_14',\n",
       " 'I_7_lag_13',\n",
       " 'I_7_lag_12',\n",
       " 'I_7_lag_11',\n",
       " 'I_7_lag_10',\n",
       " 'I_7_lag_9',\n",
       " 'I_7_lag_8',\n",
       " 'I_7_lag_7',\n",
       " 'I_7_lag_6',\n",
       " 'I_7_lag_5',\n",
       " 'I_7_lag_4',\n",
       " 'I_7_lag_3',\n",
       " 'I_7_lag_2',\n",
       " 'I_7_lag_1',\n",
       " 'I_7_lag_0',\n",
       " 'X_1_lag_20',\n",
       " 'X_1_lag_19',\n",
       " 'X_1_lag_18',\n",
       " 'X_1_lag_17',\n",
       " 'X_1_lag_16',\n",
       " 'X_1_lag_15',\n",
       " 'X_1_lag_14',\n",
       " 'X_1_lag_13',\n",
       " 'X_1_lag_12',\n",
       " 'X_1_lag_11',\n",
       " 'X_1_lag_10',\n",
       " 'X_1_lag_9',\n",
       " 'X_1_lag_8',\n",
       " 'X_1_lag_7',\n",
       " 'X_1_lag_6',\n",
       " 'X_1_lag_5',\n",
       " 'X_1_lag_4',\n",
       " 'X_1_lag_3',\n",
       " 'X_1_lag_2',\n",
       " 'X_1_lag_1',\n",
       " 'X_1_lag_0',\n",
       " 'X_2_lag_20',\n",
       " 'X_2_lag_19',\n",
       " 'X_2_lag_18',\n",
       " 'X_2_lag_17',\n",
       " 'X_2_lag_16',\n",
       " 'X_2_lag_15',\n",
       " 'X_2_lag_14',\n",
       " 'X_2_lag_13',\n",
       " 'X_2_lag_12',\n",
       " 'X_2_lag_11',\n",
       " 'X_2_lag_10',\n",
       " 'X_2_lag_9',\n",
       " 'X_2_lag_8',\n",
       " 'X_2_lag_7',\n",
       " 'X_2_lag_6',\n",
       " 'X_2_lag_5',\n",
       " 'X_2_lag_4',\n",
       " 'X_2_lag_3',\n",
       " 'X_2_lag_2',\n",
       " 'X_2_lag_1',\n",
       " 'X_2_lag_0',\n",
       " 'X_3_lag_20',\n",
       " 'X_3_lag_19',\n",
       " 'X_3_lag_18',\n",
       " 'X_3_lag_17',\n",
       " 'X_3_lag_16',\n",
       " 'X_3_lag_15',\n",
       " 'X_3_lag_14',\n",
       " 'X_3_lag_13',\n",
       " 'X_3_lag_12',\n",
       " 'X_3_lag_11',\n",
       " 'X_3_lag_10',\n",
       " 'X_3_lag_9',\n",
       " 'X_3_lag_8',\n",
       " 'X_3_lag_7',\n",
       " 'X_3_lag_6',\n",
       " 'X_3_lag_5',\n",
       " 'X_3_lag_4',\n",
       " 'X_3_lag_3',\n",
       " 'X_3_lag_2',\n",
       " 'X_3_lag_1',\n",
       " 'X_3_lag_0']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the columns to understand the construction of the dataset. \n",
    "# It begins with lag_20 and finishes with lag_0 for the 10 time series. \n",
    "# So lag_20 represent the fist day of a month set to a value of \"100\" of investment.\n",
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is up to 50 different samples (different weights) for the same time serie of 26 days \n",
    "# (21 days of training and 5 days of prediction)\n",
    "# given a train dataset of 10 000 samples, if there are exactly 50 differents, we should obtain :\n",
    "# 10 000/50 = 200 unique (values) time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 200\n",
      "1 200\n",
      "2 200\n",
      "3 200\n",
      "4 200\n",
      "5 200\n",
      "6 200\n",
      "7 200\n",
      "8 200\n",
      "9 200\n",
      "10 200\n",
      "11 200\n",
      "12 200\n",
      "13 200\n",
      "14 200\n",
      "15 200\n",
      "16 200\n",
      "17 200\n",
      "18 200\n",
      "19 193\n",
      "20 1\n"
     ]
    }
   ],
   "source": [
    "# I think any strategy I or macro feature X could allow to find the number of unique values,\n",
    "# because for 20 different variations over the 21 days, only the same variations can give a same final value\n",
    "# there is no place for hazard here. \n",
    "\n",
    "# For strategy I_1 (for example) we can find our same 200 time series starting at lag_7 (14th day of the month)\n",
    "for i in range(0,21):\n",
    "    print(i,data[\"I_2_lag_\"+str(i)].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 89\n",
      "1 89\n",
      "2 89\n",
      "3 89\n",
      "4 89\n",
      "5 89\n",
      "6 89\n",
      "7 88\n",
      "8 87\n",
      "9 87\n",
      "10 86\n",
      "11 86\n",
      "12 84\n",
      "13 84\n",
      "14 83\n",
      "15 82\n",
      "16 80\n",
      "17 80\n",
      "18 79\n",
      "19 77\n",
      "20 1\n"
     ]
    }
   ],
   "source": [
    "# Let's check for the test dataset with I_7 (for example) \n",
    "for i in range(0,21):\n",
    "    print(i,test[\"I_7_lag_\"+str(i)].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same, i find the 89 unique values expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The metric is a L1 norm with values smoothed by a fonction : f(x) = sig(x)*exp(-1/abs(x))\n",
    "# The models will be train with the smoothed values of y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "y[\"smoothed\"] = y.apply(lambda x: np.sign(x)*np.exp(-1/abs(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the customized cross_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# A difficulty here is that the different samples for a same time serie are shuffled into the dataset. \n",
    "# So I can not just randomly split the dataset into a train/val dataset. \n",
    "# I have to make sure to have different time series in train and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 289\n",
      "1 289\n",
      "2 289\n",
      "3 289\n",
      "4 285\n",
      "5 282\n",
      "6 280\n",
      "7 278\n",
      "8 277\n",
      "9 270\n",
      "10 266\n",
      "11 266\n",
      "12 262\n",
      "13 257\n",
      "14 255\n",
      "15 253\n",
      "16 250\n",
      "17 248\n",
      "18 242\n",
      "19 233\n",
      "20 1\n"
     ]
    }
   ],
   "source": [
    "# First, let's check if there are same time series in train and test \n",
    "# We have 200 unique values for train, 89 for test, if indeed time series are different\n",
    "# we should obtain 289 unique values in the concatenation oh both. \n",
    "check = pd.concat([data, test])\n",
    "for i in range(0,21):\n",
    "    print(i,check[\"I_7_lag_\"+str(i)].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now know train and test are not shuffled and correspond to different time series.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# First, I group the samples by values of I_1_lag_0 (for example) \n",
    "data_gb = data.groupby(\"I_1_lag_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Then, samples that correspond to the same time serie will have the same IDGroup\n",
    "for i, ind in enumerate(list(data_gb.groups.values())):\n",
    "    data.loc[ind,\"IDgroup\"] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "columns = data.columns.tolist()\n",
    "columns = columns[-1:]+columns[:-1]\n",
    "data = data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "id_group = data['IDgroup']\n",
    "X = data.drop(['IDgroup'], axis=1)\n",
    "gkf = GroupKFold(5)\n",
    "splits = gkf.split(data.loc[:, :], y.smoothed, id_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done ! \n",
    "# When I will run my models, i will split my different cross/val sets\n",
    "# by the GroupKFold function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's recreate the benchmark score\n",
    "# The benchmark is the average Sharpe ratio of the training period\n",
    "# The challenge doesn't specify if the train period taken is the entire train period or \n",
    "# the train period after cross_val split. \n",
    "# I choose to take the entire train period. However, this is not really important for the results. \n",
    "\n",
    "avg = y.Target.mean()\n",
    "X_benchmark = X.copy()\n",
    "X_benchmark[\"pred_benchmark\"] = np.sign(avg)*np.exp(-1/abs(avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average Sharpe ratio over the training set is : 1.2883218600109478\n",
      "The Benchmark score is : 0.5949589309692296\n"
     ]
    }
   ],
   "source": [
    "benchmark_score = mean_absolute_error(y.smoothed, X_benchmark[\"pred_benchmark\"])\n",
    "print(\"The average Sharpe ratio over the training set is :\",avg)\n",
    "print(\"The Benchmark score is :\", benchmark_score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "list_indicators = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "list_selection = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Daily Rate of Change for each strategy \n",
    "def I_roc(dataset):\n",
    "    I_roc_list = []\n",
    "    for i in range(1,8):\n",
    "        for j in range(20): \n",
    "            dataset[\"I_{}_roc_{}\".format(i,j)] = np.log(dataset[\"I_{}_lag_{}\".\n",
    "                                                                  format(i,j)]/dataset[\"I_{}_lag_{}\".format(i,j+1)])\n",
    "            I_roc_list.append(\"I_{}_roc_{}\".format(i,j))\n",
    "    return I_roc_list\n",
    "list_indicators.append(I_roc)\n",
    "list_selection.append(\"I_roc_list\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "I_roc_list = I_roc(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Monthly return for each strategy\n",
    "def I_roc20(dataset):\n",
    "    I_roc20_list = []\n",
    "    for i in range(1,8):\n",
    "        dataset[\"I_{}_roc20\".format(i)] = 0\n",
    "        I_roc20_list.append(\"I_{}_roc20\".format(i))\n",
    "        for j in range(20):\n",
    "            dataset[\"I_{}_roc20\".format(i)] += np.log(dataset[\"I_{}_lag_{}\".\n",
    "                                                format(i,j)]/dataset[\"I_{}_lag_{}\".format(i,j+1)])\n",
    "    return I_roc20_list\n",
    "list_indicators.append(I_roc20)\n",
    "list_selection.append(\"I_roc20_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "I_roc20_list = I_roc20(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# last week return for each strategy\n",
    "def I_roc5(dataset):\n",
    "    I_roc5_list = []\n",
    "    for i in range(1,8):\n",
    "        dataset[\"I_{}_roc5\".format(i)] = 0\n",
    "        I_roc5_list.append(\"I_{}_roc5\".format(i))\n",
    "        for j in range(5):\n",
    "            dataset[\"I_{}_roc5\".format(i)] += np.log(dataset[\"I_{}_lag_{}\".\n",
    "                                                format(i,j)]/dataset[\"I_{}_lag_{}\".format(i,j+1)])\n",
    "\n",
    "    return I_roc5_list\n",
    "list_indicators.append(I_roc5)\n",
    "list_selection.append(\"I_roc5_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "I_roc5_list = I_roc5(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Daily Rate of Change for each macro-economic feature \n",
    "def X_roc(dataset):    \n",
    "    X_roc_list = []\n",
    "    for i in range(1,4):\n",
    "        for j in range(20):\n",
    "            dataset[\"X_{}_roc_{}\".format(i,j)] = np.log(dataset[\"X_{}_lag_{}\".\n",
    "                                                format(i,j)]/dataset[\"X_{}_lag_{}\".format(i,j+1)])\n",
    "            X_roc_list.append(\"X_{}_roc_{}\".format(i,j))\n",
    "    return X_roc_list\n",
    "list_indicators.append(X_roc)\n",
    "list_selection.append(\"X_roc_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "X_roc_list = X_roc(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Monthly return for each macro-economic feature\n",
    "def X_roc20(dataset):\n",
    "    X_roc20_list = []\n",
    "    for i in range(1,4):\n",
    "        dataset[\"X_{}_roc20\".format(i)] = 0\n",
    "        X_roc20_list.append(\"X_{}_roc20\".format(i))\n",
    "        for j in range(20):\n",
    "            dataset[\"X_{}_roc20\".format(i)] += np.log(dataset[\"X_{}_lag_{}\".\n",
    "                                                    format(i,j)]/dataset[\"X_{}_lag_{}\".format(i,j+1)])\n",
    "    return X_roc20_list\n",
    "list_indicators.append(X_roc20)  \n",
    "list_selection.append(\"X_roc20_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "X_roc20_list = X_roc20(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# last week return for each macro-economic feature\n",
    "def X_roc5(dataset):\n",
    "    X_roc5_list = []\n",
    "    for i in range(1,4):\n",
    "        dataset[\"X_{}_roc5\".format(i)] = 0\n",
    "        X_roc5_list.append(\"X_{}_roc5\".format(i))\n",
    "        for j in range(5):\n",
    "            dataset[\"X_{}_roc5\".format(i)] += np.log(dataset[\"X_{}_lag_{}\".\n",
    "                                                format(i,j)]/dataset[\"X_{}_lag_{}\".format(i,j+1)])\n",
    "    return X_roc5_list\n",
    "list_indicators.append(X_roc5)\n",
    "list_selection.append(\"X_roc5_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "X_roc5_list = X_roc5(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Weekly rate of change shifted with a window step = 5 \n",
    "def I_roc5_shifted(dataset):\n",
    "    I_roc5_shifted_list = []\n",
    "    for s in range(1,4):\n",
    "        for i in range(1,8):\n",
    "            dataset[\"I_{}_roc5_S{}\".format(i,s)] = 0\n",
    "            I_roc5_shifted_list.append(\"I_{}_roc5_S{}\".format(i,s))\n",
    "            for j in range(5):\n",
    "                dataset[\"I_{}_roc5_S{}\".format(i,s)] += np.log(dataset[\"I_{}_lag_{}\".\n",
    "                                    format(i,j+(5*s))]/dataset[\"I_{}_lag_{}\".format(i,j+(5*s)+1)])\n",
    "    return I_roc5_shifted_list\n",
    "list_indicators.append(I_roc5_shifted)\n",
    "list_selection.append(\"I_roc5_shifted_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "I_roc5_shifted_list = I_roc5_shifted(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# last week weighted return \n",
    "def I_wr(dataset):\n",
    "    dataset[\"I_wr\"] = 0\n",
    "    for i in range(1,8):\n",
    "        for j in range(5):\n",
    "            dataset[\"I_wr\"] += (np.log(dataset[\"I_{}_lag_{}\".\n",
    "                                                format(i,j)]/dataset[\"I_{}_lag_{}\".format(i,j+1)])\n",
    "            * dataset[\"weight_I_{}\".format(i)]) * 252/5\n",
    "    return [\"I_wr\"]\n",
    "list_indicators.append(I_wr)\n",
    "list_selection.append(\"I_wr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "I_wr_list = I_wr(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Weighted rate of return for each shifted window\n",
    "# This function need \"I_roc5_shifted\" appended to the dataset first\n",
    "def I_wr_shifted(dataset):\n",
    "    I_wr_shifted_list = []\n",
    "    for s in range(1,4):\n",
    "        dataset[\"I_wr_S{}\".format(s)] = 0\n",
    "        I_wr_shifted_list.append(\"I_wr_S{}\".format(s))\n",
    "        for i in range(1,8):\n",
    "            dataset[\"I_wr_S{}\".format(s)] += (dataset[\"I_{}_roc5_S{}\".format(i,s)] * \n",
    "                                              dataset[\"weight_I_{}\".format(i)] * (252/5))\n",
    "    return I_wr_shifted_list\n",
    "list_indicators.append(I_wr_shifted)\n",
    "list_selection.append(\"I_wr_shifted_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "I_wr_shifted_list = I_wr_shifted(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Covariances of strategies I\n",
    "# This function need \"I_roc\" and \"I_roc20\" appended to the dataset first  \n",
    "def I_cov(dataset):\n",
    "    I_cov_list = []\n",
    "    for i in range(1,8):\n",
    "        for j in range(1,8):\n",
    "            dataset[\"I_cov_{}{}\".format(i,j)] = 0\n",
    "            I_cov_list.append(\"I_cov_{}{}\".format(i,j))\n",
    "            for t in range(20):\n",
    "                dataset[\"I_cov_{}{}\".format(i,j)] += ((dataset[\"I_{}_roc_{}\".format(i,t)]\n",
    "                                                      - dataset[\"I_{}_roc20\".format(i)])\n",
    "                                                     * (dataset[\"I_{}_roc_{}\".format(j,t)] \n",
    "                                                     - dataset[\"I_{}_roc20\".format(j)]))\n",
    "    return I_cov_list\n",
    "list_indicators.append(I_cov)\n",
    "list_selection.append(\"I_cov_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "I_cov_list = I_cov(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Covariances of X \n",
    "# This function need \"X_roc\" and \"X_roc20\" appended to the dataset first  \n",
    "def X_cov(dataset):\n",
    "    X_cov_list = []\n",
    "    for i in range(1,4):\n",
    "        for j in range(1,4):\n",
    "            dataset[\"X_cov_{}{}\".format(i,j)] = 0\n",
    "            X_cov_list.append(\"X_cov_{}{}\".format(i,j))\n",
    "            for t in range(20):\n",
    "                dataset[\"X_cov_{}{}\".format(i,j)] += ((dataset[\"X_{}_roc_{}\".format(i,t)]\n",
    "                                                      - dataset[\"X_{}_roc20\".format(i)])\n",
    "                                                    * (dataset[\"X_{}_roc_{}\".format(j,t)] \n",
    "                                                    - dataset[\"X_{}_roc20\".format(j)]))\n",
    "    return X_cov_list\n",
    "list_indicators.append(X_cov)\n",
    "list_selection.append(\"X_roc_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "X_cov_list = X_cov(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Volatility of blended strategies\n",
    "# This function need \"I_cov\" appended to the dataset first\n",
    "def sigma(dataset):\n",
    "    dataset[\"sigma\"] = 0\n",
    "    for i in range(1,8):\n",
    "        for j in range(1,8):\n",
    "            dataset[\"sigma\"] += (252*dataset['weight_I_{}'.format(i)]*dataset['weight_I_{}'.format(j)]\n",
    "                                * dataset[\"I_cov_{}{}\".format(i,j)])\n",
    "    dataset[\"sigma\"] = np.sqrt(dataset[\"sigma\"])\n",
    "    dataset[\"sigma\"][dataset[\"sigma\"]<0.005] = 0.005\n",
    "    return [\"sigma\"]\n",
    "list_indicators.append(sigma)\n",
    "list_selection.append(\"sigma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "sigma_list = sigma(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Sharpe ratio of the portfolio (blended strategies)\n",
    "# This function need \"sigma\" and \"I_wr\" appended to the dataset first\n",
    "def SR(dataset):\n",
    "    dataset[\"SR\"] = dataset[\"I_wr\"]/dataset[\"sigma\"]\n",
    "    return [\"SR\"]\n",
    "list_indicators.append(SR)\n",
    "list_selection.append(\"SR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "SR_list = SR(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Shifted Sharpe ratios of the portfolio \n",
    "# This function need \"sigma\" and \"I_wr_shifted\" appended to the dataset first \n",
    "def SR_shifted(dataset):\n",
    "    SR_shifted_list = []\n",
    "    for s in range(1,4):\n",
    "        dataset[\"SR_S{}\".format(s)] = dataset[\"I_wr_S{}\".format(s)]/dataset[\"sigma\"]\n",
    "        SR_shifted_list.append(\"SR_S{}\".format(s))\n",
    "    return SR_shifted_list\n",
    "list_indicators.append(SR_shifted)\n",
    "list_selection.append(\"SR_shifted_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "SR_shifted_list = SR_shifted(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Sharpe raio of each strategy alone\n",
    "# This function need \"I_cov\" and \"I_roc5\" appended to the dataset first \n",
    "def SR_I(dataset):\n",
    "    SR_I_list = []\n",
    "    for i in range(1,8):\n",
    "        dataset[\"SR_I{}\".format(i)] = np.sqrt(dataset[\"I_cov_{}{}\".format(i,i)])\n",
    "        dataset[\"SR_I{}\".format(i)][dataset[\"SR_I{}\".format(i)]<0.005] = 0.005 \n",
    "        dataset[\"SR_I{}\".format(i)] = dataset[\"I_{}_roc5\".format(i)] / dataset[\"SR_I{}\".format(i)]\n",
    "        SR_I_list.append(\"SR_I{}\".format(i))\n",
    "    return SR_I_list\n",
    "list_indicators.append(SR_I)\n",
    "list_selection.append(\"SR_I_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "SR_I_list = SR_I(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_list = [\"weight_I_1\", \"weight_I_2\", \"weight_I_3\", \"weight_I_4\", \"weight_I_5\", \"weight_I_6\", \"weight_I_7\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# list of indicators operations to run over the dataset\n",
    "indicators = [i for i in list_indicators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def engineering(dataset, indicators):\n",
    "    ''' Apply feature engineering transormations to the dataset \n",
    "    '''\n",
    "    for indicator in indicators:\n",
    "        indicator(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "engineering(X, indicators)\n",
    "engineering(test, indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I_roc_list',\n",
       " 'I_roc20_list',\n",
       " 'I_roc5_list',\n",
       " 'X_roc_list',\n",
       " 'X_roc20_list',\n",
       " 'X_roc5_list',\n",
       " 'I_roc5_shifted_list',\n",
       " 'I_wr',\n",
       " 'I_wr_shifted_list',\n",
       " 'I_cov_list',\n",
       " 'X_roc_list',\n",
       " 'sigma',\n",
       " 'SR',\n",
       " 'SR_shifted_list',\n",
       " 'SR_I_list']"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of all the functions created \n",
    "list_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = weights_list+SR_list+I_wr_list+I_cov_list+I_roc20_list+I_roc5_list+X_roc20_list\n",
    "#selection = SR_I_list+I_roc20_list+X_roc20_list+SR_shifted_list+X_cov_list+SR_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = Pipeline(\n",
    "#    [\n",
    "#        ('selector', SelectKBest(f_regression)),\n",
    "#        ('model', xgb)\n",
    "#    ]\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params_xgb = {'selector__k':[10,20,30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search = GridSearchCV(\n",
    "#    estimator = pipeline,\n",
    "#    param_grid = params_xgb,\n",
    "#    scoring = 'neg_mean_absolute_error',\n",
    "#    cv = 5\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x1a3ae0d450>,\n",
       "             error_score=nan,\n",
       "             estimator=HistGradientBoostingRegressor(l2_regularization=0.15,\n",
       "                                                     learning_rate=0.1,\n",
       "                                                     loss='least_squares',\n",
       "                                                     max_bins=255, max_depth=2,\n",
       "                                                     max_iter=100,\n",
       "                                                     max_leaf_nodes=31,\n",
       "                                                     min_samples_leaf=20,\n",
       "                                                     n_iter_no_change=None,\n",
       "                                                     random_state=None,\n",
       "                                                     scoring=None, tol=1e-07,\n",
       "                                                     validation_fraction=0.1,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.2, 0.21],\n",
       "                         'max_iter': [50, 100, 150],\n",
       "                         'max_leaf_nodes': [15, 30, 50],\n",
       "                         'min_samples_leaf': [5, 8, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkf = GroupKFold(5)\n",
    "params = {\n",
    "    'learning_rate': [0.2, 0.21],\n",
    "    'min_samples_leaf': [5, 8, 10],\n",
    "    'max_iter': [50, 100, 150],\n",
    "    'max_leaf_nodes': [15, 30, 50]\n",
    "}\n",
    "\n",
    "search_gb = GridSearchCV(HistGradientBoostingRegressor(max_depth=2,\n",
    "                                                 l2_regularization=0.15),\n",
    "                      params,\n",
    "                      scoring='neg_mean_absolute_error',\n",
    "                      n_jobs= -1,\n",
    "                      cv=gkf.split(X.loc[:, :], y.smoothed, id_group))\n",
    "search_gb.fit(X[selection], y.smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2,\n",
       " 'max_iter': 100,\n",
       " 'max_leaf_nodes': 15,\n",
       " 'min_samples_leaf': 10}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5693022395097986"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3689537876662926, 0.5782751818924042)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_model = []\n",
    "train_res = []\n",
    "test_res = []\n",
    "\n",
    "gkf = GroupKFold(5)\n",
    "for i, (train_index, test_index) in enumerate(gkf.split(X.loc[:, :], y.smoothed, id_group)):\n",
    "        train_X_fold = X.iloc[train_index, :].loc[:, selection].values \n",
    "        train_Y_fold = y.smoothed.iloc[train_index].values\n",
    "        test_X_fold = X.iloc[test_index, :].loc[:, selection].values\n",
    "        test_Y_fold = y.smoothed.iloc[test_index].values\n",
    "               \n",
    "        gb = HistGradientBoostingRegressor(max_depth=2, l2_regularization=0.15,\n",
    "                                          min_samples_leaf=10, learning_rate=0.2,\n",
    "                                          max_leaf_nodes=15)\n",
    "        gb.fit(train_X_fold, train_Y_fold)\n",
    "        \n",
    "        train_preds = gb.predict(train_X_fold)\n",
    "        test_preds = gb.predict(test_X_fold)\n",
    "        mae_train = mean_absolute_error(train_Y_fold, train_preds)\n",
    "        mae_test = mean_absolute_error(test_Y_fold, test_preds)\n",
    "        train_res.append(mae_train)\n",
    "        test_res.append(mae_test)\n",
    "        \n",
    "        gb_model.append(gb)\n",
    "        \n",
    "np.mean(train_res), np.mean(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission = gb.predict(test[selection])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"pred\"] = test_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"fpred\"] = np.sign(test['pred']) * np.exp(-1/abs(test['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fpred.to_csv(\"submissions/submission_gb.csv\")\n",
    "test = test.drop([\"pred\",\"fpred\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2182598812178496, 2.4468991644057936)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = []\n",
    "train_res = []\n",
    "test_res = []\n",
    "\n",
    "gkf = GroupKFold(5)\n",
    "for i, (train_index, test_index) in enumerate(gkf.split(X.loc[:, :], y.smoothed, id_group)):\n",
    "        train_X_fold = X.iloc[train_index, :].loc[:, selection].values\n",
    "        train_Y_fold = y.iloc[train_index].values\n",
    "        test_X_fold = X.iloc[test_index, :].loc[:, selection].values\n",
    "        test_Y_fold = y.iloc[test_index].values\n",
    "        \n",
    "        rf = RandomForestRegressor(criterion='mae', max_depth=2, n_jobs=-1)\n",
    "        rf.fit(train_X_fold, train_Y_fold)\n",
    "        \n",
    "        train_preds = rf.predict(train_X_fold)\n",
    "        test_preds = rf.predict(test_X_fold)\n",
    "        mae_train = mean_absolute_error(train_Y_fold, train_preds)\n",
    "        mae_test = mean_absolute_error(test_Y_fold, test_preds)\n",
    "        train_res.append(mae_train)\n",
    "        test_res.append(mae_test)\n",
    "        \n",
    "        rf_model.append(rf)\n",
    "        \n",
    "np.mean(train_res), np.mean(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(5):\n",
    "    models.append(load('./model_dir/' + 'model_' + str(i) + '.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for model in models:\n",
    "    res = model.predict(X[selection])\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -0.536672\n",
       "1       0.404113\n",
       "2       0.425993\n",
       "3       0.348289\n",
       "4       0.597408\n",
       "          ...   \n",
       "9995    0.119318\n",
       "9996    0.287358\n",
       "9997    0.609562\n",
       "9998    0.569162\n",
       "9999   -0.045909\n",
       "Length: 10000, dtype: float64"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res_df = pd.DataFrame(results).T\n",
    "test_res_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47465698789036276"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y.smoothed, np.sign(test_res_df.mean(axis=1))*np.exp(-1/abs(np.sign(test_res_df.mean(axis=1)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for model in models:\n",
    "    res = model.predict(test[selection])\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.550146\n",
       "1       0.152546\n",
       "2       0.312853\n",
       "3       0.283591\n",
       "4       0.064488\n",
       "          ...   \n",
       "4445    0.314462\n",
       "4446    0.180333\n",
       "4447    0.190934\n",
       "4448    0.128698\n",
       "4449    0.004498\n",
       "Length: 4450, dtype: float64"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res_df = pd.DataFrame(results).T\n",
    "test_res_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"pred\"] = test_res_df.mean(axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.pred.to_csv(\"submissions/submission_rf_mean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_depth=2, criterion=\"mae\")\n",
    "rfr_2 = RandomForestRegressor(max_depth=2, criterion=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 53s, sys: 862 ms, total: 1min 54s\n",
      "Wall time: 2min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
       "                      max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rfr.fit(X_train_6, y_train.smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_pred_train = rfr.predict(X_train_6)\n",
    "rfr_pred_val = rfr.predict(X_val_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_6[\"rf_pred\"] = rfr_pred_train\n",
    "X_val_6[\"rf_pred\"] = rfr_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5154500736560105\n",
      "0.6154748131897437\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(X_train_6.rf_pred, y_train.smoothed))\n",
    "print(mean_absolute_error(X_val_6.rf_pred, y_val.smoothed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training of the model on the entire train dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
       "                      max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=2, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_2.fit(data_4, target.smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_full_train = rfr_2.predict(data_4)\n",
    "rf_pred = rfr_2.predict(test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4[\"pred\"] = rf_pred_full_train\n",
    "test_4[\"pred\"] = rf_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4[\"fpred\"] = np.sign(data_4['pred']) * np.exp(-1/abs(data_4['pred']))\n",
    "test_4[\"fpred\"] = np.sign(test_4['pred']) * np.exp(-1/abs(test_4['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.513401905044875"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y.smoothed, data_4.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_4.fpred.to_csv(\"submission_rf_pred_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:54:46] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x1a38315cd0>,\n",
       "             error_score=nan,\n",
       "             estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                    colsample_bylevel=1, colsample_bynode=1,\n",
       "                                    colsample_bytree=1, gamma=0,\n",
       "                                    importance_type='gain', learning_rate=0.1,\n",
       "                                    max_delta_step=0, max_depth=2,\n",
       "                                    min_child_weight=1, missing=None,\n",
       "                                    n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                    objectiv..., random_state=0,\n",
       "                                    reg_alpha=0, reg_lambda=1,\n",
       "                                    scale_pos_weight=1, seed=None, silent=None,\n",
       "                                    subsample=1, verbosity=1),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2, 0.21],\n",
       "                         'reg_alpha': [1, 95, 100, 150, 200],\n",
       "                         'reg_lambda': [1, 95, 100, 150, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkf = GroupKFold(5)\n",
    "params = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.21],\n",
    "    'reg_alpha' : [1, 50, 95, 100, 150, 200],\n",
    "    'reg_lambda': [0.1, 1, 2],\n",
    "}\n",
    "\n",
    "search_xgb = GridSearchCV(XGBRegressor(max_depth=2,\n",
    "                                                 ),\n",
    "                      params,\n",
    "                      scoring='neg_mean_absolute_error', \n",
    "                      n_jobs= -1,\n",
    "                      cv=gkf.split(X.loc[:, :], y.smoothed, id_group))\n",
    "search_xgb.fit(X[selection], y.smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2, 'reg_alpha': 95, 'reg_lambda': 1}"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.572466509438496"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_xgb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:43:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:43:27] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:43:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:43:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:43:31] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.43935302144029703, 0.5569483189674088)"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = []\n",
    "train_res = []\n",
    "test_res = []\n",
    "\n",
    "gkf = GroupKFold(5)\n",
    "for i, (train_index, test_index) in enumerate(gkf.split(X.loc[:, :], y.smoothed, id_group)):\n",
    "        train_X_fold = X.iloc[train_index, :].loc[:, selection].values\n",
    "        train_Y_fold = y.smoothed.iloc[train_index].values\n",
    "        test_X_fold = X.iloc[test_index, :].loc[:, selection].values\n",
    "        test_Y_fold = y.smoothed.iloc[test_index].values\n",
    "        \n",
    "        xgb = XGBRegressor(max_depth=2, n_jobs=-1, \n",
    "                           learning_rate = 0.2, \n",
    "                           reg_alpha = 80, \n",
    "                           reg_lambda = 1)\n",
    "        \n",
    "        xgb.fit(train_X_fold, train_Y_fold)\n",
    "        \n",
    "        train_preds = xgb.predict(train_X_fold)\n",
    "        test_preds = xgb.predict(test_X_fold)\n",
    "        mae_train = mean_absolute_error(train_Y_fold, train_preds)\n",
    "        mae_test = mean_absolute_error(test_Y_fold, test_preds)\n",
    "        train_res.append(mae_train)\n",
    "        test_res.append(mae_test)\n",
    "        \n",
    "        xgb_model.append(xgb)\n",
    "        \n",
    "np.mean(train_res), np.mean(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred_train = xgb.predict(X[selection].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"pred\"] = xgb_pred_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4753883545317744"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y.smoothed, X.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pd.DataFrame({\"x\":range(1,11), \"y1\":y.smoothed[1:11], \"y2\":X.pred[1:11]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.scatter(\"x\",\"y1\", data=graph, color='skyblue', )\n",
    "plt.scatter(\"x\",\"y2\", data=graph, color='orange')\n",
    "plt.legend([\"Real\",\"Prediction\"])\n",
    "plt.title(\"10 first Sharpe ratio values\")\n",
    "plt.show();\n",
    "fig.savefig(\"graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"fpred\"] = np.sign(X.pred)*np.exp(-1/abs(X.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5813801941071568\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y.smoothed, X.fpred))\n",
    "X = X.drop([\"pred\",\"fpred\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred = xgb.predict(test[selection].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"pred\"] = xgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.pred.to_csv(\"submissions/submission_xgb_mean5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"fpred\"] = np.sign(test.pred)*np.exp(-1/abs(test.pred))\n",
    "test = test.drop([\"pred\",\"fpred\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:07:13] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x1a3bab0dd0>,\n",
       "             error_score=nan,\n",
       "             estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                    colsample_bylevel=1, colsample_bynode=1,\n",
       "                                    colsample_bytree=1, gamma=0,\n",
       "                                    importance_type='gain', learning_rate=0.1,\n",
       "                                    max_delta_step=0, max_depth=2,\n",
       "                                    min_child_weight=1, missing=None,\n",
       "                                    n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                    objective='reg:linear', random_state=0,\n",
       "                                    reg_alpha=0, reg_lambda=1,\n",
       "                                    scale_pos_weight=1, seed=None, silent=None,\n",
       "                                    subsample=1, verbosity=1),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'reg_alpha': [45, 49, 50, 50.5],\n",
       "                         'reg_lambda': [0.1, 1, 2]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkf = GroupKFold(5)\n",
    "params = {\n",
    "    #'learning_rate' : [0.01, 0.1, 0.2, 0.21],\n",
    "    #'max_depth' : [2,3],\n",
    "    'reg_alpha' : [45, 49, 50, 50.5],\n",
    "    'reg_lambda': [0.1, 1, 2],\n",
    "}\n",
    "\n",
    "search_xgb = GridSearchCV(XGBRegressor(max_depth=2,\n",
    "                                                 ),\n",
    "                      params,\n",
    "                      scoring='neg_mean_absolute_error', \n",
    "                      n_jobs= -1,\n",
    "                      cv=gkf.split(X.loc[:, :], y.smoothed, id_group))\n",
    "search_xgb.fit(X[selection], y.smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_alpha': 49, 'reg_lambda': 1}"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:07:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:07:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:07:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:07:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:07:31] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.40469801477718087, 0.5565668385756537)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = []\n",
    "train_res = []\n",
    "test_res = []\n",
    "\n",
    "gkf = GroupKFold(5)\n",
    "for i, (train_index, test_index) in enumerate(gkf.split(X.loc[:, :], y.smoothed, id_group)):\n",
    "        train_X_fold = X.iloc[train_index, :].loc[:, selection].values\n",
    "        train_Y_fold = y.smoothed.iloc[train_index].values\n",
    "        test_X_fold = X.iloc[test_index, :].loc[:, selection].values\n",
    "        test_Y_fold = y.smoothed.iloc[test_index].values\n",
    "        \n",
    "        xgb = XGBRegressor(max_depth=2, n_jobs=-1, \n",
    "                           learning_rate = 0.2, \n",
    "                           reg_alpha = 49, \n",
    "                           reg_lambda = 1)\n",
    "        \n",
    "        xgb.fit(train_X_fold, train_Y_fold)\n",
    "        \n",
    "        train_preds = xgb.predict(train_X_fold)\n",
    "        test_preds = xgb.predict(test_X_fold)\n",
    "        mae_train = mean_absolute_error(train_Y_fold, train_preds)\n",
    "        mae_test = mean_absolute_error(test_Y_fold, test_preds)\n",
    "        train_res.append(mae_train)\n",
    "        test_res.append(mae_test)\n",
    "        \n",
    "        xgb_model.append(xgb)\n",
    "        \n",
    "np.mean(train_res), np.mean(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Univariate model / xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_I1 = X_train.loc[:,\"I_1_lag_20\":\"I_1_lag_0\"]\n",
    "X_train_I2 = X_train.loc[:,\"I_2_lag_20\":\"I_2_lag_0\"]\n",
    "X_train_I3 = X_train.loc[:,\"I_3_lag_20\":\"I_3_lag_0\"]\n",
    "X_train_I4 = X_train.loc[:,\"I_4_lag_20\":\"I_4_lag_0\"]\n",
    "X_train_I5 = X_train.loc[:,\"I_5_lag_20\":\"I_5_lag_0\"]\n",
    "X_train_I6 = X_train.loc[:,\"I_6_lag_20\":\"I_6_lag_0\"]\n",
    "X_train_I7 = X_train.loc[:,\"I_7_lag_20\":\"I_7_lag_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_I1 = X_val.loc[:,\"I_1_lag_20\":\"I_1_lag_0\"]\n",
    "X_val_I2 = X_val.loc[:,\"I_2_lag_20\":\"I_2_lag_0\"]\n",
    "X_val_I3 = X_val.loc[:,\"I_3_lag_20\":\"I_3_lag_0\"]\n",
    "X_val_I4 = X_val.loc[:,\"I_4_lag_20\":\"I_4_lag_0\"]\n",
    "X_val_I5 = X_val.loc[:,\"I_5_lag_20\":\"I_5_lag_0\"]\n",
    "X_val_I6 = X_val.loc[:,\"I_6_lag_20\":\"I_6_lag_0\"]\n",
    "X_val_I7 = X_val.loc[:,\"I_7_lag_20\":\"I_7_lag_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_I1 = test.loc[:,\"I_1_lag_20\":\"I_1_lag_0\"]\n",
    "X_test_I2 = test.loc[:,\"I_2_lag_20\":\"I_2_lag_0\"]\n",
    "X_test_I3 = test.loc[:,\"I_3_lag_20\":\"I_3_lag_0\"]\n",
    "X_test_I4 = test.loc[:,\"I_4_lag_20\":\"I_4_lag_0\"]\n",
    "X_test_I5 = test.loc[:,\"I_5_lag_20\":\"I_5_lag_0\"]\n",
    "X_test_I6 = test.loc[:,\"I_6_lag_20\":\"I_6_lag_0\"]\n",
    "X_test_I7 = test.loc[:,\"I_7_lag_20\":\"I_7_lag_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_I1 = sc_x.fit_transform(X_train_I1)\n",
    "X_train_I2 = sc_x.fit_transform(X_train_I2)\n",
    "X_train_I3 = sc_x.fit_transform(X_train_I3)\n",
    "X_train_I4 = sc_x.fit_transform(X_train_I4)\n",
    "X_train_I5 = sc_x.fit_transform(X_train_I5)\n",
    "X_train_I6 = sc_x.fit_transform(X_train_I6)\n",
    "X_train_I7 = sc_x.fit_transform(X_train_I7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_I1 = sc_x.transform(X_val_I1)\n",
    "X_val_I2 = sc_x.transform(X_val_I2)\n",
    "X_val_I3 = sc_x.transform(X_val_I3)\n",
    "X_val_I4 = sc_x.transform(X_val_I4)\n",
    "X_val_I5 = sc_x.transform(X_val_I5)\n",
    "X_val_I6 = sc_x.transform(X_val_I6)\n",
    "X_val_I7 = sc_x.transform(X_val_I7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_I1 = sc_x.transform(X_test_I1)\n",
    "X_test_I2 = sc_x.transform(X_test_I2)\n",
    "X_test_I3 = sc_x.transform(X_test_I3)\n",
    "X_test_I4 = sc_x.transform(X_test_I4)\n",
    "X_test_I5 = sc_x.transform(X_test_I5)\n",
    "X_test_I6 = sc_x.transform(X_test_I6)\n",
    "X_test_I7 = sc_x.transform(X_test_I7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_I1 = np.expand_dims(X_train_I1, axis=-1)\n",
    "X_train_I2 = np.expand_dims(X_train_I2, axis=-1)\n",
    "X_train_I3 = np.expand_dims(X_train_I3, axis=-1)\n",
    "X_train_I4 = np.expand_dims(X_train_I4, axis=-1)\n",
    "X_train_I5 = np.expand_dims(X_train_I5, axis=-1)\n",
    "X_train_I6 = np.expand_dims(X_train_I6, axis=-1)\n",
    "X_train_I7 = np.expand_dims(X_train_I7, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_I1 = np.expand_dims(X_val_I1, axis=-1)\n",
    "X_val_I2 = np.expand_dims(X_val_I2, axis=-1)\n",
    "X_val_I3 = np.expand_dims(X_val_I3, axis=-1)\n",
    "X_val_I4 = np.expand_dims(X_val_I4, axis=-1)\n",
    "X_val_I5 = np.expand_dims(X_val_I5, axis=-1)\n",
    "X_val_I6 = np.expand_dims(X_val_I6, axis=-1)\n",
    "X_val_I7 = np.expand_dims(X_val_I7, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_I1 = np.expand_dims(X_test_I1, axis=-1)\n",
    "X_test_I2 = np.expand_dims(X_test_I2, axis=-1)\n",
    "X_test_I3 = np.expand_dims(X_test_I3, axis=-1)\n",
    "X_test_I4 = np.expand_dims(X_test_I4, axis=-1)\n",
    "X_test_I5 = np.expand_dims(X_test_I5, axis=-1)\n",
    "X_test_I6 = np.expand_dims(X_test_I6, axis=-1)\n",
    "X_test_I7 = np.expand_dims(X_test_I7, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 158\n",
    "BUFFER_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_univariate_1 = tf.data.Dataset.from_tensor_slices((X_train_I1, y_train.smoothed)).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_univariate_2 = tf.data.Dataset.from_tensor_slices((X_train_I2, y_train.smoothed)).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_univariate_3 = tf.data.Dataset.from_tensor_slices((X_train_I3, y_train.smoothed)).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_univariate_4 = tf.data.Dataset.from_tensor_slices((X_train_I4, y_train.smoothed)).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_univariate_5 = tf.data.Dataset.from_tensor_slices((X_train_I5, y_train.smoothed)).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_univariate_6 = tf.data.Dataset.from_tensor_slices((X_train_I6, y_train.smoothed)).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_univariate_7 = tf.data.Dataset.from_tensor_slices((X_train_I7, y_train.smoothed)).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_univariate_1 = tf.data.Dataset.from_tensor_slices((X_val_I1, y_val.smoothed)).batch(BATCH_SIZE).repeat()\n",
    "val_univariate_2 = tf.data.Dataset.from_tensor_slices((X_val_I2, y_val.smoothed)).batch(BATCH_SIZE).repeat()\n",
    "val_univariate_3 = tf.data.Dataset.from_tensor_slices((X_val_I3, y_val.smoothed)).batch(BATCH_SIZE).repeat()\n",
    "val_univariate_4 = tf.data.Dataset.from_tensor_slices((X_val_I4, y_val.smoothed)).batch(BATCH_SIZE).repeat()\n",
    "val_univariate_5 = tf.data.Dataset.from_tensor_slices((X_val_I5, y_val.smoothed)).batch(BATCH_SIZE).repeat()\n",
    "val_univariate_6 = tf.data.Dataset.from_tensor_slices((X_val_I6, y_val.smoothed)).batch(BATCH_SIZE).repeat()\n",
    "val_univariate_7 = tf.data.Dataset.from_tensor_slices((X_val_I7, y_val.smoothed)).batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_univariate_1.take(1))\n",
    "y_train.smoothed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_lstm_model_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=X_train_I1.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "simple_lstm_model_2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=X_train_I1.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "simple_lstm_model_3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=X_train_I1.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "simple_lstm_model_4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=X_train_I1.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "simple_lstm_model_5 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=X_train_I1.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "simple_lstm_model_6 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=X_train_I1.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "simple_lstm_model_7 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=X_train_I1.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_lstm_model_1.compile(optimizer='adam', loss='mae', metrics=[R2])\n",
    "simple_lstm_model_2.compile(optimizer='adam', loss='mae', metrics=[R2])\n",
    "simple_lstm_model_3.compile(optimizer='adam', loss='mae', metrics=[R2])\n",
    "simple_lstm_model_4.compile(optimizer='adam', loss='mae', metrics=[R2])\n",
    "simple_lstm_model_5.compile(optimizer='adam', loss='mae', metrics=[R2])\n",
    "simple_lstm_model_6.compile(optimizer='adam', loss='mae', metrics=[R2])\n",
    "simple_lstm_model_7.compile(optimizer='adam', loss='mae', metrics=[R2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x, _ in val_univariate.take(1):\n",
    "    print(simple_lstm_model.predict(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_INTERVAL = 10\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = simple_lstm_model_1.fit(train_univariate_1, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate_1, validation_steps=50)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "history_2 = simple_lstm_model_2.fit(train_univariate_2, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate_2, validation_steps=50)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "history_3 = simple_lstm_model_3.fit(train_univariate_3, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate_3, validation_steps=50)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "history_4 = simple_lstm_model_4.fit(train_univariate_4, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate_4, validation_steps=50)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "history_5 = simple_lstm_model_5.fit(train_univariate_5, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate_5, validation_steps=50)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "history_6 = simple_lstm_model_6.fit(train_univariate_6, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate_6, validation_steps=50)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "history_7 = simple_lstm_model_7.fit(train_univariate_7, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate_7, validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_2.history[\"loss\"], color=\"b\", label=\"Training Loss\")\n",
    "plt.plot(history_2.history[\"val_loss\"], color=\"r\", label=\"Validation Loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"R2\"], color=\"b\", label = \"Training R2\")\n",
    "plt.plot(history.history[\"val_R2\"], color=\"r\", label =\"Validation R2\")\n",
    "plt.ylabel(\"R2\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on train values\n",
    "lstm_pred_I1 = simple_lstm_model_1.predict(X_train_I1)\n",
    "lstm_pred_I2 = simple_lstm_model_2.predict(X_train_I2)\n",
    "lstm_pred_I3 = simple_lstm_model_3.predict(X_train_I3)\n",
    "lstm_pred_I4 = simple_lstm_model_4.predict(X_train_I4)\n",
    "lstm_pred_I5 = simple_lstm_model_5.predict(X_train_I5)\n",
    "lstm_pred_I6 = simple_lstm_model_6.predict(X_train_I6)\n",
    "lstm_pred_I7 = simple_lstm_model_7.predict(X_train_I7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on validation values\n",
    "lstm_val_pred_I1 = simple_lstm_model_1.predict(X_val_I1)\n",
    "lstm_val_pred_I2 = simple_lstm_model_2.predict(X_val_I2)\n",
    "lstm_val_pred_I3 = simple_lstm_model_3.predict(X_val_I3)\n",
    "lstm_val_pred_I4 = simple_lstm_model_4.predict(X_val_I4)\n",
    "lstm_val_pred_I5 = simple_lstm_model_5.predict(X_val_I5)\n",
    "lstm_val_pred_I6 = simple_lstm_model_6.predict(X_val_I6)\n",
    "lstm_val_pred_I7 = simple_lstm_model_7.predict(X_val_I7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on test values\n",
    "lstm_test_pred_I1 = simple_lstm_model_1.predict(X_test_I1)\n",
    "lstm_test_pred_I2 = simple_lstm_model_2.predict(X_test_I2)\n",
    "lstm_test_pred_I3 = simple_lstm_model_3.predict(X_test_I3)\n",
    "lstm_test_pred_I4 = simple_lstm_model_4.predict(X_test_I4)\n",
    "lstm_test_pred_I5 = simple_lstm_model_5.predict(X_test_I5)\n",
    "lstm_test_pred_I6 = simple_lstm_model_6.predict(X_test_I6)\n",
    "lstm_test_pred_I7 = simple_lstm_model_7.predict(X_test_I7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = {\"lstm_pred_I1\":lstm_pred_I1[:,0], \"lstm_pred_I2\":lstm_pred_I2[:,0], \"lstm_pred_I3\":lstm_pred_I3[:,0],\n",
    "    \"lstm_pred_I4\":lstm_pred_I4[:,0], \"lstm_pred_I5\":lstm_pred_I5[:,0], \"lstm_pred_I6\":lstm_pred_I6[:,0], \n",
    "     \"lstm_pred_I7\":lstm_pred_I7[:,0]}\n",
    "lstm_I_train = pd.DataFrame(data=d_train, index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_wI_train = pd.concat([X_train.iloc[:,0:7], lstm_I_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_val = {\"lstm_pred_I1\":lstm_val_pred_I1[:,0], \"lstm_pred_I2\":lstm_val_pred_I2[:,0], \"lstm_pred_I3\":lstm_val_pred_I3[:,0],\n",
    "    \"lstm_pred_I4\":lstm_val_pred_I4[:,0], \"lstm_pred_I5\":lstm_val_pred_I5[:,0], \"lstm_pred_I6\":lstm_val_pred_I6[:,0], \n",
    "     \"lstm_pred_I7\":lstm_val_pred_I7[:,0]}\n",
    "lstm_I_val = pd.DataFrame(data=d_val, index=X_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_wI_val = pd.concat([X_val.iloc[:,0:7], lstm_I_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_wI_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = {\"lstm_pred_I1\":lstm_test_pred_I1[:,0], \"lstm_pred_I2\":lstm_test_pred_I2[:,0], \"lstm_pred_I3\":lstm_test_pred_I3[:,0],\n",
    "    \"lstm_pred_I4\":lstm_test_pred_I4[:,0], \"lstm_pred_I5\":lstm_test_pred_I5[:,0], \"lstm_pred_I6\":lstm_test_pred_I6[:,0], \n",
    "     \"lstm_pred_I7\":lstm_test_pred_I7[:,0]}\n",
    "lstm_I_test = pd.DataFrame(data=d_test, index=test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_wI_test = pd.concat([test.iloc[:,0:7], lstm_I_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train an adaboost on the lstm predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = AdaBoostRegressor()\n",
    "adaboost.fit(lstm_wI_train, y_train.smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_train_pred = adaboost.predict(lstm_wI_train)\n",
    "ada_val_pred = adaboost.predict(lstm_wI_val)\n",
    "ada_test_pred = adaboost.predict(lstm_wI_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_wI_train[\"pred\"] = ada_train_pred\n",
    "lstm_wI_val[\"pred\"] = ada_val_pred\n",
    "lstm_wI_test[\"pred\"] = ada_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_wI_train[\"fpred\"] = np.sign(lstm_wI_train[\"pred\"])*np.exp(-1/abs(lstm_wI_train[\"pred\"]))\n",
    "lstm_wI_val[\"fpred\"] = np.sign(lstm_wI_val[\"pred\"])*np.exp(-1/abs(lstm_wI_val[\"pred\"]))\n",
    "lstm_wI_test[\"fpred\"] = np.sign(lstm_wI_test[\"pred\"])*np.exp(-1/abs(lstm_wI_test[\"pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(y_train.smoothed,lstm_wI_train[\"fpred\"]))\n",
    "print(mean_absolute_error(y_val.smoothed,lstm_wI_val[\"fpred\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission of the lstm/adaboost model on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_wI_test.fpred.to_csv(\"submission_lstm_adaboost\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "217px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
