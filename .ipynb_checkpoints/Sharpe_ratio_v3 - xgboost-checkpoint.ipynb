{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Prediction of Sharpe ratio for blends of quantitative strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor \n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true,
    "hide_input": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Data/Training_Input_2dx8C9Q.csv\")\n",
    "target = pd.read_csv(\"Data/Training_Output_IJhBXtA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"Data/Testing_Input_dPKY3Rf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "data = data.set_index(\"ID\")\n",
    "target = target.set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "test = test.set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-12.007941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.294867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.652308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.412364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.517471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Target\n",
       "ID           \n",
       "0  -12.007941\n",
       "1    2.294867\n",
       "2    0.652308\n",
       "3    2.412364\n",
       "4    8.517471"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Missing values ?\n",
    "print(True in data.isna(), True in target.isna(), True in test.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's see the columns to understand the construction of the dataset. \n",
    "# It begins with lag_20 and finishes with lag_0 for the 10 time series. \n",
    "# So lag_20 represent the fist day of a month set to a value of \"100\" of investment.\n",
    "for i in data.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# There is up to 50 different samples (different weights) for the same time serie of 26 days \n",
    "# (21 days of training and 5 days of prediction)\n",
    "# given a train dataset of 10 000 samples, if there are exactly 50 differents, we should obtain :\n",
    "# 10 000/50 = 200 unique (values) time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# I think any strategy I or macro feature X could allow to find the number of unique values,\n",
    "# because for 20 different variations over the 21 days, only the same variations can give a same final value\n",
    "# there is no place for hazard here. \n",
    "\n",
    "# For macro indicator X_1 (for example) we can find our same 200 time series starting at lag_18 (3rd day of the month)\n",
    "for i in range(0,21):\n",
    "    print(i,data[\"X_1_lag_\"+str(i)].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's check for the test dataset with I_7 (for example) \n",
    "for i in range(0,21):\n",
    "    print(i,test[\"I_7_lag_\"+str(i)].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the customized cross_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# A difficulty here is that the different samples for a same time serie are shuffled into the dataset. \n",
    "# So I can not just randomly split the dataset into a train/val datasets. \n",
    "# I have to make sure to have different time series in train and validation.\n",
    "# So let's make our own cross_val. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's check if there are same time series in train and test \n",
    "# We have 200 unique values for train, 89 for test, if indeed time series are different\n",
    "# we should obtain 289 unique values in the concatenation oh both. \n",
    "check = pd.concat([data, test])\n",
    "for i in range(0,21):\n",
    "    print(i,check[\"I_7_lag_\"+str(i)].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now know train and test are not shuffled and correspond to different time series.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Let's split train/val by values of X1_lag_0 (for example), as there are 200 unique values\n",
    "values = data.X_1_lag_0.unique()\n",
    "train, val = train_test_split(values, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "full_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# I add the target to split its values the same way as for features. \n",
    "full_data[\"target\"] = target.Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# By filtering on train and val unique values, I can apply the split on the entire dataset\n",
    "df_train = full_data[data.X_1_lag_0.isin(train)]\n",
    "df_val = full_data[data.X_1_lag_0.isin(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7500 entries, 0 to 9999\n",
      "Columns: 530 entries, weight_I_1 to target\n",
      "dtypes: float64(530)\n",
      "memory usage: 30.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2500 entries, 2 to 9998\n",
      "Columns: 530 entries, weight_I_1 to target\n",
      "dtypes: float64(530)\n",
      "memory usage: 10.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_val.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "X_train = df_train.drop([\"target\"],axis=1)\n",
    "y_train = df_train.loc[:,[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "X_val = df_val.drop([\"target\"],axis=1)\n",
    "y_val = df_val.loc[:,[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "y_train[\"smoothed\"] = np.sign(y_train[\"target\"])*np.exp(-1/abs(y_train[\"target\"]))\n",
    "y_val[\"smoothed\"] = np.sign(y_val[\"target\"])*np.exp(-1/abs(y_val[\"target\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's recreate the benchmark score\n",
    "# The benchmark is the average Sharpe ratio of the training period\n",
    "# The metric is a L1 norm with values smoothed by a fonction : f(x) = sig(x)*exp(-1/abs(x))\n",
    "\n",
    "#avg = y_train.target.mean()\n",
    "avg = target.Target.mean()\n",
    "X_train_benchmark = X_train.copy()\n",
    "X_val_benchmark = X_val.copy()\n",
    "X_train_benchmark[\"pred_benchmark\"] = np.sign(avg)*np.exp(-1/abs(avg))\n",
    "X_val_benchmark[\"pred_benchmark\"] = np.sign(avg)*np.exp(-1/abs(avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "benchmark_train_score = mean_absolute_error(y_train[\"smoothed\"], X_train_benchmark[\"pred_benchmark\"])\n",
    "benchmark_val_score =  mean_absolute_error(y_val[\"smoothed\"], X_val_benchmark[\"pred_benchmark\"])\n",
    "print(\"The average Sharpe ratio over the training set is :\",avg)\n",
    "print(\"Benchmark train score: {}, Benchmark validation score: {}\".format(benchmark_train_score, benchmark_val_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor(criterion = \"mae\", max_depth=2)\n",
    "dtr.fit(X_train, y_train.smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred_train = dtr.predict(X_train)\n",
    "y_pred_val = dtr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dtr_train_score = mean_absolute_error(y_train.smoothed, y_pred_train)\n",
    "dtr_val_score = mean_absolute_error(y_val.smoothed, y_pred_val)\n",
    "print(dtr_train_score, dtr_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_feature_importances(model, Frame):\n",
    "    plt.clf()\n",
    "    n_features=len(Frame.columns)\n",
    "    plt.figure(figsize=(10,100))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), Frame.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target[\"smoothed\"] = np.sign(target[\"Target\"])*np.exp(-1/abs(target[\"Target\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_depth=2, criterion=\"mae\", random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 11s, sys: 2.18 s, total: 7min 13s\n",
      "Wall time: 7min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
       "                      max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=2, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rfr.fit(data_rf, target.smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rfr_pred_train = rfr_2.predict(X_train_norm)\n",
    "rfr_pred_val = rfr_2.predict(X_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_pred_train = rfr.predict(data_rf)\n",
    "rf_pred = rfr.predict(test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(mean_absolute_error(rfr_pred_train, y_train.smoothed))\n",
    "print(mean_absolute_error(rfr_pred_val, y_val.smoothed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train[\"pred\"] = rfr_pred_train\n",
    "X_val[\"pred\"] = rfr_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_rf[\"pred\"] = rf_pred_train\n",
    "test_rf[\"pred\"] = rf_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train[\"fpred\"] = np.sign(X_train[\"pred\"])*np.exp(-1/abs(X_train[\"pred\"]))\n",
    "X_val[\"fpred\"] = np.sign(X_val[\"pred\"])*np.exp(-1/abs(X_val[\"pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_rf[\"fpred\"] = -np.sign(data_rf['pred'])/(np.log(abs(data_rf['pred'])))\n",
    "#data_rf[\"fpred\"] = np.sign(data_rf['pred'])* np.exp(-1/abs(data_rf['pred']))\n",
    "test_rf[\"fpred\"] = -np.sign(test_rf['pred'])/(np.log(abs(test_rf['pred'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5792647390486836"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(target.smoothed, data_rf.fpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_rf.fpred.to_csv(\"submission_rf_pred_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(mean_absolute_error(X_train.fpred, y_train.smoothed), mean_absolute_error(X_val.fpred, y_val.smoothed))\n",
    "X_train = X_train.drop([\"pred\",\"fpred\"], axis=1)\n",
    "X_val = X_val.drop([\"pred\",\"fpred\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb_2 = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:37:23] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_2.fit(X_train_xgb, y_train.smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb_pred_train = xgb_2.predict(X_train_xgb)\n",
    "xgb_pred_val = xgb_2.predict(X_val_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_xgb[\"pred\"] = xgb_pred_train\n",
    "X_val_xgb[\"pred\"] = xgb_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35204926450015933\n",
      "0.5303315033120306\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(X_train_xgb.pred, y_train.smoothed))\n",
    "print(mean_absolute_error(X_val_xgb.pred, y_val.smoothed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_xgb[\"fpred\"] = np.sign(X_train_xgb[\"pred\"])*np.exp(-1/abs(X_train_xgb[\"pred\"]))\n",
    "X_val_xgb[\"fpred\"] = np.sign(X_val_xgb[\"pred\"])*np.exp(-1/abs(X_val_xgb[\"pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5406433351653317\n",
      "0.5806568335701102\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(X_train_xgb.fpred, y_train.smoothed))\n",
    "print(mean_absolute_error(X_val_xgb.fpred, y_val.smoothed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "xgb.fit(data_rf, target.smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb_pred = xgb.predict(data_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_rf[\"pred\"] = xgb_pred\n",
    "data_rf[\"fpred\"] = np.sign(data_rf['pred'])* np.exp(-1/abs(data_rf['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.368835986301781\n",
      "0.5425651188313596\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(data_rf.pred, target.smoothed))\n",
    "print(mean_absolute_error(data_rf.fpred, target.smoothed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Linear Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sc_x = StandardScaler()\n",
    "X_train_norm = sc_x.fit_transform(X_train)\n",
    "X_val_norm = sc_x.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "elastic_net = ElasticNet(alpha= 1, l1_ratio= 0)\n",
    "elastic_net.fit(X_train, y_train.smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "elast_pred_train = elastic_net.predict(X_train)\n",
    "elast_pred_val = elastic_net.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train[\"pred\"] = elast_pred_train\n",
    "X_val[\"pred\"] = elast_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train[\"fpred\"] = np.sign(X_train[\"pred\"])*np.exp(-1/abs(X_train[\"pred\"]))\n",
    "X_val[\"fpred\"] = np.sign(X_val[\"pred\"])*np.exp(-1/abs(X_val[\"pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mean_absolute_error(X_train.fpred, y_train.smoothed), mean_absolute_error(X_val.fpred, y_val.smoothed))\n",
    "X_train = X_train.drop([\"pred\",\"fpred\"], axis=1)\n",
    "X_val = X_val.drop([\"pred\",\"fpred\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {'alpha' : [0.01, 1, 5, 10], 'l1_ratio' : [0, 1]}\n",
    "reg = ElasticNet()\n",
    "grid = GridSearchCV(reg,param_grid=params, cv = 5)\n",
    "\n",
    "grid.fit(X_train_norm, y_train.smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(mean_absolute_error(grid.predict(X_train_norm), y_train.smoothed))\n",
    "mean_absolute_error(grid.predict(X_val_norm), y_val.smoothed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### ElasticNet with feature selection pipeline and GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('selector', SelectKBest(f_regression)),\n",
    "        ('model',ElasticNet())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params_elasticnet = {'selector__k':[10,100,150,200,215], 'model__alpha' : [0.01, 1, 5, 10], 'model__l1_ratio' : [0, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "search = GridSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_grid = params_elasticnet,\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    cv = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "search.fit(X_train_norm, y_train.smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(mean_absolute_error(search.predict(X_train_norm), y_train.smoothed))\n",
    "print(mean_absolute_error(search.predict(X_val_norm), y_val.smoothed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### LSTM Univariate model / xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_I1 = X_train.loc[:,\"I_1_lag_20\":\"I_1_lag_0\"]\n",
    "X_train_I2 = X_train.loc[:,\"I_2_lag_20\":\"I_2_lag_0\"]\n",
    "X_train_I3 = X_train.loc[:,\"I_3_lag_20\":\"I_3_lag_0\"]\n",
    "X_train_I4 = X_train.loc[:,\"I_4_lag_20\":\"I_4_lag_0\"]\n",
    "X_train_I5 = X_train.loc[:,\"I_5_lag_20\":\"I_5_lag_0\"]\n",
    "X_train_I6 = X_train.loc[:,\"I_6_lag_20\":\"I_6_lag_0\"]\n",
    "X_train_I7 = X_train.loc[:,\"I_7_lag_20\":\"I_7_lag_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_val_I1 = X_val.loc[:,\"I_1_lag_20\":\"I_1_lag_0\"]\n",
    "X_val_I2 = X_val.loc[:,\"I_2_lag_20\":\"I_2_lag_0\"]\n",
    "X_val_I3 = X_val.loc[:,\"I_3_lag_20\":\"I_3_lag_0\"]\n",
    "X_val_I4 = X_val.loc[:,\"I_4_lag_20\":\"I_4_lag_0\"]\n",
    "X_val_I5 = X_val.loc[:,\"I_5_lag_20\":\"I_5_lag_0\"]\n",
    "X_val_I6 = X_val.loc[:,\"I_6_lag_20\":\"I_6_lag_0\"]\n",
    "X_val_I7 = X_val.loc[:,\"I_7_lag_20\":\"I_7_lag_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test_I1 = test.loc[:,\"I_1_lag_20\":\"I_1_lag_0\"]\n",
    "X_test_I2 = test.loc[:,\"I_2_lag_20\":\"I_2_lag_0\"]\n",
    "X_test_I3 = test.loc[:,\"I_3_lag_20\":\"I_3_lag_0\"]\n",
    "X_test_I4 = test.loc[:,\"I_4_lag_20\":\"I_4_lag_0\"]\n",
    "X_test_I5 = test.loc[:,\"I_5_lag_20\":\"I_5_lag_0\"]\n",
    "X_test_I6 = test.loc[:,\"I_6_lag_20\":\"I_6_lag_0\"]\n",
    "X_test_I7 = test.loc[:,\"I_7_lag_20\":\"I_7_lag_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_I1 = sc_x.fit_transform(X_train_I1)\n",
    "X_train_I2 = sc_x.fit_transform(X_train_I2)\n",
    "X_train_I3 = sc_x.fit_transform(X_train_I3)\n",
    "X_train_I4 = sc_x.fit_transform(X_train_I4)\n",
    "X_train_I5 = sc_x.fit_transform(X_train_I5)\n",
    "X_train_I6 = sc_x.fit_transform(X_train_I6)\n",
    "X_train_I7 = sc_x.fit_transform(X_train_I7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_val_I1 = sc_x.transform(X_val_I1)\n",
    "X_val_I2 = sc_x.transform(X_val_I2)\n",
    "X_val_I3 = sc_x.transform(X_val_I3)\n",
    "X_val_I4 = sc_x.transform(X_val_I4)\n",
    "X_val_I5 = sc_x.transform(X_val_I5)\n",
    "X_val_I6 = sc_x.transform(X_val_I6)\n",
    "X_val_I7 = sc_x.transform(X_val_I7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test_I1 = sc_x.transform(X_test_I1)\n",
    "X_test_I2 = sc_x.transform(X_test_I2)\n",
    "X_test_I3 = sc_x.transform(X_test_I3)\n",
    "X_test_I4 = sc_x.transform(X_test_I4)\n",
    "X_test_I5 = sc_x.transform(X_test_I5)\n",
    "X_test_I6 = sc_x.transform(X_test_I6)\n",
    "X_test_I7 = sc_x.transform(X_test_I7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_I1 = np.expand_dims(X_train_I1, axis=-1)\n",
    "X_train_I2 = np.expand_dims(X_train_I2, axis=-1)\n",
    "X_train_I3 = np.expand_dims(X_train_I3, axis=-1)\n",
    "X_train_I4 = np.expand_dims(X_train_I4, axis=-1)\n",
    "X_train_I5 = np.expand_dims(X_train_I5, axis=-1)\n",
    "X_train_I6 = np.expand_dims(X_train_I6, axis=-1)\n",
    "X_train_I7 = np.expand_dims(X_train_I7, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_val_I1 = np.expand_dims(X_val_I1, axis=-1)\n",
    "X_val_I2 = np.expand_dims(X_val_I2, axis=-1)\n",
    "X_val_I3 = np.expand_dims(X_val_I3, axis=-1)\n",
    "X_val_I4 = np.expand_dims(X_val_I4, axis=-1)\n",
    "X_val_I5 = np.expand_dims(X_val_I5, axis=-1)\n",
    "X_val_I6 = np.expand_dims(X_val_I6, axis=-1)\n",
    "X_val_I7 = np.expand_dims(X_val_I7, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test_I1 = np.expand_dims(X_test_I1, axis=-1)\n",
    "X_test_I2 = np.expand_dims(X_test_I2, axis=-1)\n",
    "X_test_I3 = np.expand_dims(X_test_I3, axis=-1)\n",
    "X_test_I4 = np.expand_dims(X_test_I4, axis=-1)\n",
    "X_test_I5 = np.expand_dims(X_test_I5, axis=-1)\n",
    "X_test_I6 = np.expand_dims(X_test_I6, axis=-1)\n",
    "X_test_I7 = np.expand_dims(X_test_I7, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 158\n",
    "BUFFER_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_univariate_1 = tf.data.Dataset.from_tensor_slices((X_train_I1, y_train.smoothed)).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_univariate_2 = tf.data.Dataset.from_tensor_slices((X_train_I2, y_train.smoothed)).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_univariate_3 = tf.data.Dataset.from_tensor_slices((X_train_I3, y_train.smoothed)).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_univariate_4 = tf.data.Dataset.from_tensor_slices((X_train_I4, y_train.smoothed)).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_univariate_5 = tf.data.Dataset.from_tensor_slices((X_train_I5, y_train.smoothed)).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_univariate_6 = tf.data.Dataset.from_tensor_slices((X_train_I6, y_train.smoothed)).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_univariate_7 = tf.data.Dataset.from_tensor_slices((X_train_I7, y_train.smoothed)).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_univariate_1 = tf.data.Dataset.from_tensor_slices((X_val_I1, y_val.smoothed)).batch(BATCH_SIZE).repeat()\n",
    "val_univariate_2 = tf.data.Dataset.from_tensor_slices((X_val_I2, y_val.smoothed)).batch(BATCH_SIZE).repeat()\n",
    "val_univariate_3 = tf.data.Dataset.from_tensor_slices((X_val_I3, y_val.smoothed)).batch(BATCH_SIZE).repeat()\n",
    "val_univariate_4 = tf.data.Dataset.from_tensor_slices((X_val_I4, y_val.smoothed)).batch(BATCH_SIZE).repeat()\n",
    "val_univariate_5 = tf.data.Dataset.from_tensor_slices((X_val_I5, y_val.smoothed)).batch(BATCH_SIZE).repeat()\n",
    "val_univariate_6 = tf.data.Dataset.from_tensor_slices((X_val_I6, y_val.smoothed)).batch(BATCH_SIZE).repeat()\n",
    "val_univariate_7 = tf.data.Dataset.from_tensor_slices((X_val_I7, y_val.smoothed)).batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(val_univariate_1.take(1))\n",
    "y_train.smoothed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def R2(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "simple_lstm_model_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=X_train_I1.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "simple_lstm_model_2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=X_train_I1.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "simple_lstm_model_3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=X_train_I1.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "simple_lstm_model_4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=X_train_I1.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "simple_lstm_model_5 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=X_train_I1.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "simple_lstm_model_6 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=X_train_I1.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "simple_lstm_model_7 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=X_train_I1.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "simple_lstm_model_1.compile(optimizer='adam', loss='mae', metrics=[R2])\n",
    "simple_lstm_model_2.compile(optimizer='adam', loss='mae', metrics=[R2])\n",
    "simple_lstm_model_3.compile(optimizer='adam', loss='mae', metrics=[R2])\n",
    "simple_lstm_model_4.compile(optimizer='adam', loss='mae', metrics=[R2])\n",
    "simple_lstm_model_5.compile(optimizer='adam', loss='mae', metrics=[R2])\n",
    "simple_lstm_model_6.compile(optimizer='adam', loss='mae', metrics=[R2])\n",
    "simple_lstm_model_7.compile(optimizer='adam', loss='mae', metrics=[R2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x, _ in val_univariate.take(1):\n",
    "    print(simple_lstm_model.predict(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EVALUATION_INTERVAL = 10\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "history_1 = simple_lstm_model_1.fit(train_univariate_1, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate_1, validation_steps=50)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "history_2 = simple_lstm_model_2.fit(train_univariate_2, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate_2, validation_steps=50)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "history_3 = simple_lstm_model_3.fit(train_univariate_3, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate_3, validation_steps=50)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "history_4 = simple_lstm_model_4.fit(train_univariate_4, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate_4, validation_steps=50)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "history_5 = simple_lstm_model_5.fit(train_univariate_5, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate_5, validation_steps=50)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "history_6 = simple_lstm_model_6.fit(train_univariate_6, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate_6, validation_steps=50)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "history_7 = simple_lstm_model_7.fit(train_univariate_7, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate_7, validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history_2.history[\"loss\"], color=\"b\", label=\"Training Loss\")\n",
    "plt.plot(history_2.history[\"val_loss\"], color=\"r\", label=\"Validation Loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"R2\"], color=\"b\", label = \"Training R2\")\n",
    "plt.plot(history.history[\"val_R2\"], color=\"r\", label =\"Validation R2\")\n",
    "plt.ylabel(\"R2\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# prediction on train values\n",
    "lstm_pred_I1 = simple_lstm_model_1.predict(X_train_I1)\n",
    "lstm_pred_I2 = simple_lstm_model_2.predict(X_train_I2)\n",
    "lstm_pred_I3 = simple_lstm_model_3.predict(X_train_I3)\n",
    "lstm_pred_I4 = simple_lstm_model_4.predict(X_train_I4)\n",
    "lstm_pred_I5 = simple_lstm_model_5.predict(X_train_I5)\n",
    "lstm_pred_I6 = simple_lstm_model_6.predict(X_train_I6)\n",
    "lstm_pred_I7 = simple_lstm_model_7.predict(X_train_I7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# prediction on validation values\n",
    "lstm_val_pred_I1 = simple_lstm_model_1.predict(X_val_I1)\n",
    "lstm_val_pred_I2 = simple_lstm_model_2.predict(X_val_I2)\n",
    "lstm_val_pred_I3 = simple_lstm_model_3.predict(X_val_I3)\n",
    "lstm_val_pred_I4 = simple_lstm_model_4.predict(X_val_I4)\n",
    "lstm_val_pred_I5 = simple_lstm_model_5.predict(X_val_I5)\n",
    "lstm_val_pred_I6 = simple_lstm_model_6.predict(X_val_I6)\n",
    "lstm_val_pred_I7 = simple_lstm_model_7.predict(X_val_I7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# prediction on test values\n",
    "lstm_test_pred_I1 = simple_lstm_model_1.predict(X_test_I1)\n",
    "lstm_test_pred_I2 = simple_lstm_model_2.predict(X_test_I2)\n",
    "lstm_test_pred_I3 = simple_lstm_model_3.predict(X_test_I3)\n",
    "lstm_test_pred_I4 = simple_lstm_model_4.predict(X_test_I4)\n",
    "lstm_test_pred_I5 = simple_lstm_model_5.predict(X_test_I5)\n",
    "lstm_test_pred_I6 = simple_lstm_model_6.predict(X_test_I6)\n",
    "lstm_test_pred_I7 = simple_lstm_model_7.predict(X_test_I7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d_train = {\"lstm_pred_I1\":lstm_pred_I1[:,0], \"lstm_pred_I2\":lstm_pred_I2[:,0], \"lstm_pred_I3\":lstm_pred_I3[:,0],\n",
    "    \"lstm_pred_I4\":lstm_pred_I4[:,0], \"lstm_pred_I5\":lstm_pred_I5[:,0], \"lstm_pred_I6\":lstm_pred_I6[:,0], \n",
    "     \"lstm_pred_I7\":lstm_pred_I7[:,0]}\n",
    "lstm_I_train = pd.DataFrame(data=d_train, index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lstm_wI_train = pd.concat([X_train.iloc[:,0:7], lstm_I_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d_val = {\"lstm_pred_I1\":lstm_val_pred_I1[:,0], \"lstm_pred_I2\":lstm_val_pred_I2[:,0], \"lstm_pred_I3\":lstm_val_pred_I3[:,0],\n",
    "    \"lstm_pred_I4\":lstm_val_pred_I4[:,0], \"lstm_pred_I5\":lstm_val_pred_I5[:,0], \"lstm_pred_I6\":lstm_val_pred_I6[:,0], \n",
    "     \"lstm_pred_I7\":lstm_val_pred_I7[:,0]}\n",
    "lstm_I_val = pd.DataFrame(data=d_val, index=X_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lstm_wI_val = pd.concat([X_val.iloc[:,0:7], lstm_I_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lstm_wI_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d_test = {\"lstm_pred_I1\":lstm_test_pred_I1[:,0], \"lstm_pred_I2\":lstm_test_pred_I2[:,0], \"lstm_pred_I3\":lstm_test_pred_I3[:,0],\n",
    "    \"lstm_pred_I4\":lstm_test_pred_I4[:,0], \"lstm_pred_I5\":lstm_test_pred_I5[:,0], \"lstm_pred_I6\":lstm_test_pred_I6[:,0], \n",
    "     \"lstm_pred_I7\":lstm_test_pred_I7[:,0]}\n",
    "lstm_I_test = pd.DataFrame(data=d_test, index=test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lstm_wI_test = pd.concat([test.iloc[:,0:7], lstm_I_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's train an adaboost on the lstm predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "adaboost = AdaBoostRegressor()\n",
    "adaboost.fit(lstm_wI_train, y_train.smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ada_train_pred = adaboost.predict(lstm_wI_train)\n",
    "ada_val_pred = adaboost.predict(lstm_wI_val)\n",
    "ada_test_pred = adaboost.predict(lstm_wI_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lstm_wI_train[\"pred\"] = ada_train_pred\n",
    "lstm_wI_val[\"pred\"] = ada_val_pred\n",
    "lstm_wI_test[\"pred\"] = ada_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lstm_wI_train[\"fpred\"] = np.sign(lstm_wI_train[\"pred\"])*np.exp(-1/abs(lstm_wI_train[\"pred\"]))\n",
    "lstm_wI_val[\"fpred\"] = np.sign(lstm_wI_val[\"pred\"])*np.exp(-1/abs(lstm_wI_val[\"pred\"]))\n",
    "lstm_wI_test[\"fpred\"] = np.sign(lstm_wI_test[\"pred\"])*np.exp(-1/abs(lstm_wI_test[\"pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(mean_absolute_error(y_train.smoothed,lstm_wI_train[\"fpred\"]))\n",
    "print(mean_absolute_error(y_val.smoothed,lstm_wI_val[\"fpred\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Submission of the lstm/adaboost model on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lstm_wI_test.fpred.to_csv(\"submission_lstm_adaboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "X_train = df_train.drop([\"target\"],axis=1)\n",
    "y_train = df_train.loc[:,[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "X_val = df_val.drop([\"target\"],axis=1)\n",
    "y_val = df_val.loc[:,[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Daily Rate of Change for each strategy \n",
    "def I_roc(dataset):\n",
    "    I_roc_list = []\n",
    "    for i in range(1,8):\n",
    "        for j in range(20): \n",
    "            dataset[\"I_{}_roc_{}\".format(i,j)] = np.log(dataset[\"I_{}_lag_{}\".\n",
    "                                                                  format(i,j)]/dataset[\"I_{}_lag_{}\".format(i,j+1)])\n",
    "            I_roc_list.append(\"I_{}_roc_{}\".format(i,j))\n",
    "    return I_roc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "I_roc_list = I_roc(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Monthly return for each strategy\n",
    "def I_roc20(dataset):\n",
    "    I_roc20_list = []\n",
    "    for i in range(1,8):\n",
    "        dataset[\"I_{}_roc20\".format(i)] = 0\n",
    "        I_roc20_list.append(\"I_{}_roc20\".format(i))\n",
    "        for j in range(20):\n",
    "            dataset[\"I_{}_roc20\".format(i)] += np.log(dataset[\"I_{}_lag_{}\".\n",
    "                                                                  format(i,j)]/dataset[\"I_{}_lag_{}\".format(i,j+1)])\n",
    "    return I_roc20_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "I_roc20_list = I_roc20(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# last week return for each strategy\n",
    "def I_roc5(dataset):\n",
    "    I_roc5_list = []\n",
    "    for i in range(1,8):\n",
    "        dataset[\"I_{}_roc5\".format(i)] = 0\n",
    "        I_roc5_list.append(\"I_{}_roc5\".format(i))\n",
    "        for j in range(5):\n",
    "            dataset[\"I_{}_roc5\".format(i)] += np.log(dataset[\"I_{}_lag_{}\".\n",
    "                                                                  format(i,j)]/dataset[\"I_{}_lag_{}\".format(i,j+1)])\n",
    "    return I_roc5_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "I_roc5_list = I_roc5(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Daily Rate of Change for each macro-economic feature \n",
    "def X_roc(dataset):    \n",
    "    X_roc_list = []\n",
    "    for i in range(1,4):\n",
    "        for j in range(20):\n",
    "            dataset[\"X_{}_roc_{}\".format(i,j)] = np.log(dataset[\"X_{}_lag_{}\".\n",
    "                                                                  format(i,j)]/dataset[\"X_{}_lag_{}\".format(i,j+1)])\n",
    "            X_roc_list.append(\"X_{}_roc_{}\".format(i,j))\n",
    "    return X_roc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "X_roc_list = X_roc(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Monthly return for each macro-economic feature\n",
    "def X_roc20(dataset):\n",
    "    X_roc20_list = []\n",
    "    for i in range(1,4):\n",
    "        dataset[\"X_{}_roc20\".format(i)] = 0\n",
    "        X_roc20_list.append(\"X_{}_roc20\".format(i))\n",
    "        for j in range(20):\n",
    "            dataset[\"X_{}_roc20\".format(i)] += np.log(dataset[\"X_{}_lag_{}\".\n",
    "                                                              format(i,j)]/dataset[\"X_{}_lag_{}\".format(i,j+1)])\n",
    "    return X_roc20_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "X_roc20_list = X_roc20(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# last week return for each macro-economic feature\n",
    "def X_roc5(dataset):\n",
    "    X_roc5_list = []\n",
    "    for i in range(1,4):\n",
    "        dataset[\"X_{}_roc5\".format(i)] = 0\n",
    "        X_roc5_list.append(\"X_{}_roc5\".format(i))\n",
    "        for j in range(5):\n",
    "            dataset[\"X_{}_roc5\".format(i)] += np.log(dataset[\"X_{}_lag_{}\".\n",
    "                                                                  format(i,j)]/dataset[\"X_{}_lag_{}\".format(i,j+1)])\n",
    "    return X_roc5_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "X_roc5_list = X_roc5(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Weekly rate of change shifted with a window step = 5 \n",
    "def I_roc5_shifted(dataset):\n",
    "    I_roc5_shifted_list = []\n",
    "    for s in range(1,4):\n",
    "        for i in range(1,8):\n",
    "            dataset[\"I_{}_roc5_S{}\".format(i,s)] = 0\n",
    "            I_roc5_shifted_list.append(\"I_{}_roc5_S{}\".format(i,s))\n",
    "            for j in range(5):\n",
    "                dataset[\"I_{}_roc5_S{}\".format(i,s)] += np.log(dataset[\"I_{}_lag_{}\".\n",
    "                                                     format(i,j+(5*s))]/dataset[\"I_{}_lag_{}\".format(i,j+(5*s)+1)])\n",
    "    return I_roc5_shifted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "I_roc5_shifted_list = I_roc5_shifted(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# last week weighted return \n",
    "def I_wr(dataset):\n",
    "    dataset[\"I_wr\"] = 0\n",
    "    for i in range(1,8):\n",
    "        for j in range(5):\n",
    "            dataset[\"I_wr\"] += (np.log(dataset[\"I_{}_lag_{}\".\n",
    "                                                         format(i,j)]/dataset[\"I_{}_lag_{}\".format(i,j+1)])\n",
    "            * dataset[\"weight_I_{}\".format(i)]) * 252/5\n",
    "    return [\"I_wr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "I_wr_list = I_wr(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Weighted rate of return for each shifted window\n",
    "# This function need \"I_roc5_shifted\" appended to the dataset first\n",
    "def I_wr_shifted(dataset):\n",
    "    I_wr_shifted_list = []\n",
    "    for s in range(1,4):\n",
    "        dataset[\"I_wr_S{}\".format(s)] = 0\n",
    "        I_wr_shifted_list.append(\"I_wr_S{}\".format(s))\n",
    "        for i in range(1,8):\n",
    "            dataset[\"I_wr_S{}\".format(s)] += (dataset[\"I_{}_roc5_S{}\".format(i,s)] * \n",
    "                                              dataset[\"weight_I_{}\".format(i)] * (252/5))\n",
    "    return I_wr_shifted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "I_wr_shifted_list = I_wr_shifted(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "hidden": true,
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cov of strategies I\n",
    "# This function need \"I_roc\" and \"I_roc20\" appended to the dataset first  \n",
    "def I_cov(dataset):\n",
    "    I_cov_list = []\n",
    "    for i in range(1,8):\n",
    "        for j in range(1,8):\n",
    "            dataset[\"I_cov_{}{}\".format(i,j)] = 0\n",
    "            I_cov_list.append(\"I_cov_{}{}\".format(i,j))\n",
    "            for t in range(20):\n",
    "                dataset[\"I_cov_{}{}\".format(i,j)] += ((dataset[\"I_{}_roc_{}\".format(i,t)]\n",
    "                                                      - dataset[\"I_{}_roc20\".format(i)])\n",
    "                                                     * (dataset[\"I_{}_roc_{}\".format(j,t)] \n",
    "                                                     - dataset[\"I_{}_roc20\".format(j)]))\n",
    "    return I_cov_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "I_cov_list = I_cov(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Cov of X \n",
    "# This function need \"X_roc\" and \"X_roc20\" appended to the dataset first  \n",
    "def X_cov(dataset):\n",
    "    X_cov_list = []\n",
    "    for i in range(1,4):\n",
    "        for j in range(1,4):\n",
    "            dataset[\"X_cov_{}{}\".format(i,j)] = 0\n",
    "            X_cov_list.append(\"X_cov_{}{}\".format(i,j))\n",
    "            for t in range(20):\n",
    "                dataset[\"X_cov_{}{}\".format(i,j)] += ((dataset[\"X_{}_roc_{}\".format(i,t)]\n",
    "                                                      - dataset[\"X_{}_roc20\".format(i)])\n",
    "                                                    * (dataset[\"X_{}_roc_{}\".format(j,t)] \n",
    "                                                    - dataset[\"X_{}_roc20\".format(j)]))\n",
    "    return X_cov_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "X_cov_list = X_cov(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Volatility of blended strategies\n",
    "# This function need \"I_cov\" appended to the dataset first\n",
    "def sigma(dataset):\n",
    "    dataset[\"sigma\"] = 0\n",
    "    for i in range(1,8):\n",
    "        for j in range(1,8):\n",
    "            dataset[\"sigma\"] += (252*dataset['weight_I_{}'.format(i)]*dataset['weight_I_{}'.format(j)]\n",
    "                                * dataset[\"I_cov_{}{}\".format(i,j)])\n",
    "    dataset[\"sigma\"] = np.sqrt(dataset[\"sigma\"])\n",
    "    dataset[\"sigma\"][dataset[\"sigma\"]<0.005] = 0.005\n",
    "    return [\"sigma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "sigma_list = sigma(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Sharpe ratio of the portfolio (blended strategies)\n",
    "# This function need \"sigma\" and \"I_wr\" appended to the dataset first\n",
    "def SR(dataset):\n",
    "    dataset[\"SR\"] = dataset[\"I_wr\"]/dataset[\"sigma\"]\n",
    "    return [\"SR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "SR_list = SR(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Shifted Sharpe ratios of the portfolio \n",
    "# This function need \"sigma\" and \"I_wr_shifted\" appended to the dataset first \n",
    "def SR_shifted(dataset):\n",
    "    SR_shifted_list = []\n",
    "    for s in range(1,4):\n",
    "        dataset[\"SR_S{}\".format(s)] = dataset[\"I_wr_S{}\".format(s)]/dataset[\"sigma\"]\n",
    "        SR_shifted_list.append(\"SR_S{}\".format(s))\n",
    "    return SR_shifted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "SR_shifted_list = SR_shifted(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Sharpe raio of each strategy alone\n",
    "# This function need \"I_cov\" and \"I_roc5\" appended to the dataset first \n",
    "def SR_I(dataset):\n",
    "    SR_I_list = []\n",
    "    for i in range(1,8):\n",
    "        dataset[\"SR_I{}\".format(i)] = np.sqrt(dataset[\"I_cov_{}{}\".format(i,i)])\n",
    "        dataset[\"SR_I{}\".format(i)][dataset[\"SR_I{}\".format(i)]<0.005] = 0.005 \n",
    "        dataset[\"SR_I{}\".format(i)] = dataset[\"I_{}_roc5\".format(i)] / dataset[\"SR_I{}\".format(i)]\n",
    "        SR_I_list.append(\"SR_I{}\".format(i))\n",
    "    return SR_I_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "SR_I_list = SR_I(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop([\"target\"],axis=1)\n",
    "y_train = df_train.loc[:,[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_val.drop([\"target\"],axis=1)\n",
    "y_val = df_val.loc[:,[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of indicators operations to append to the dataset\n",
    "indicators = [I_roc, I_roc20, I_roc5, I_roc5_shifted, I_cov, SR_I, X_roc, X_roc20, sigma, I_wr_shifted, SR_shifted, X_cov, I_wr, SR]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineering(dataset, indicators):\n",
    "    ''' Append the indicators to the dataset \n",
    "    '''\n",
    "    for indicator in indicators:\n",
    "        indicator(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineering(X_train, indicators)\n",
    "engineering(X_val, indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineering(data, indicators)\n",
    "engineering(test, indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of indicators list to keep\n",
    "selection = SR_I_list+I_roc20_list+X_roc20_list+SR_shifted_list+X_cov_list+SR_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_xgb = X_train[selection]\n",
    "X_val_xgb = X_val[selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = data[selection]\n",
    "test_rf = test[selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "217px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
